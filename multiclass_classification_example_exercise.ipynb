{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sbCbx9-WWj3"
      },
      "source": [
        "**Classifying newswires: a multiclass classification example**\n",
        "\n",
        "Fill in code at \"#TODO\" places and run the code!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrJEmF6_Wd8H"
      },
      "source": [
        "#Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8ZvoBbcAWQuV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-04 02:03:44.985587: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-04 02:03:46.487881: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2110848/2110848 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\n",
        "    num_words=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8jHtfpqeYOom"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8982,), (2246,))"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.shape, test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MZLy1JuAYWxO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979, 3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]\n"
          ]
        }
      ],
      "source": [
        "print(train_data[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cLNwYfKyYtCe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "550378/550378 [==============================] - 0s 0us/step\n",
            "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
          ]
        }
      ],
      "source": [
        "# Decode newswires back to text\n",
        "word_index = reuters.get_word_index()\n",
        "reverse_word_index = dict(\n",
        "    [(value, key) for (key, value) in word_index.items()]\n",
        ")\n",
        "decode_review = \" \".join(\n",
        "    [reverse_word_index.get(i - 3, \"?\") for i in train_data[0]]\n",
        ")\n",
        "print(decode_review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wie60x0KZ-kw"
      },
      "source": [
        "Note: \"0\" - Padding. \"1\" - Start of sequence. \"2\" - Unknown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylWcY0g-Wh0y"
      },
      "source": [
        "#Prepare the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcR9kDi3abP8"
      },
      "source": [
        "**Encoding the integer sequence via multi-host encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Squf6oCjWkDe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Prepaer inputs by using multi-hot encoding\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    for j in sequence:\n",
        "      results[i, j] = 1.\n",
        "  return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)\n",
        "\n",
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FciW6SudcMKh"
      },
      "outputs": [],
      "source": [
        "# Prepare outputs by using one-hot encoding\n",
        "\n",
        "def to_one_hot(labels, dimension=46):\n",
        "  results = np.zeros((len(labels), dimension))\n",
        "  for i, label in enumerate(labels):\n",
        "    results[i, label] = 1.\n",
        "  return results\n",
        "\n",
        "y_train = to_one_hot(train_labels)\n",
        "y_test = to_one_hot(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3INS6GRukmW"
      },
      "source": [
        "Note: it can also use the built-in function in Keras:\n",
        "```\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(train_labels)\n",
        "y_test = to_categorical(test_labels)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8ucaY7vWkeX"
      },
      "source": [
        "#Build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVWumCEdcsSw"
      },
      "source": [
        "**Define the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EBDYkKXAWn9P"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-04 02:03:51.395729: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-04 02:03:51.591475: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-04 02:03:51.591552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-04 02:03:51.597632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-04 02:03:51.597725: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-04 02:03:51.597755: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-04 02:03:53.661195: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-04 02:03:53.661307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-04 02:03:53.661322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "2023-10-04 02:03:53.661385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-04 02:03:53.661476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3413 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the model #TODO\n",
        "model = keras.Sequential(\n",
        "    [#TODO,\n",
        "     #TODO,\n",
        "     #TODO\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvjunMlKcwmH"
      },
      "source": [
        "**Compile the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MmzIsmVMc2mj"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Unknown optimizer: '#TODO'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/staticowl/winHome/Code/myProjects/Scratchpad/multiclass_classification_example_exercise.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/staticowl/winHome/Code/myProjects/Scratchpad/multiclass_classification_example_exercise.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Compile the model #TODO\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/staticowl/winHome/Code/myProjects/Scratchpad/multiclass_classification_example_exercise.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mcompile(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/staticowl/winHome/Code/myProjects/Scratchpad/multiclass_classification_example_exercise.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     optimizer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m#TODO\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/staticowl/winHome/Code/myProjects/Scratchpad/multiclass_classification_example_exercise.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     loss\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m#TODO\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/staticowl/winHome/Code/myProjects/Scratchpad/multiclass_classification_example_exercise.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     metrics\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39m#TODO\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/staticowl/winHome/Code/myProjects/Scratchpad/multiclass_classification_example_exercise.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
            "File \u001b[0;32m~/.local/bin/.virtualenvs/tf/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/.local/bin/.virtualenvs/tf/lib/python3.10/site-packages/keras/src/saving/legacy/serialization.py:365\u001b[0m, in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m object_registration\u001b[39m.\u001b[39mget_registered_object(\n\u001b[1;32m    362\u001b[0m     class_name, custom_objects, module_objects\n\u001b[1;32m    363\u001b[0m )\n\u001b[1;32m    364\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 365\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    366\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown \u001b[39m\u001b[39m{\u001b[39;00mprintable_module_name\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    367\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure you are using a `keras.utils.custom_object_scope` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    368\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand that this object is included in the scope. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    369\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    370\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#registering_the_custom_object for details.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m     )\n\u001b[1;32m    373\u001b[0m cls_config \u001b[39m=\u001b[39m config[\u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    374\u001b[0m \u001b[39m# Check if `cls_config` is a list. If it is a list, return the class and the\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[39m# associated class configs for recursively deserialization. This case will\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[39m# happen on the old version of sequential model (e.g. `keras_version` ==\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[39m# \"2.0.6\"), which is serialized in a different structure, for example\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[39m# \"{'class_name': 'Sequential',\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[39m#   'config': [{'class_name': 'Embedding', 'config': ...}, {}, ...]}\".\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown optimizer: '#TODO'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
          ]
        }
      ],
      "source": [
        "# Compile the model #TODO\n",
        "model.compile(\n",
        "    optimizer=\"#TODO\",\n",
        "    loss=\"#TODO\",\n",
        "    metrics=[\"#TODO\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xuORvz1WoNi"
      },
      "source": [
        "#Validate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ECF9KHDdoUH"
      },
      "source": [
        "**Fit the model with a validation set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qYqirZ4Wzh_"
      },
      "outputs": [],
      "source": [
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "y_val = y_train[:1000]\n",
        "partial_y_train = y_train[1000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZjBU3qPe9gn"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    partial_x_train,\n",
        "    partial_y_train,\n",
        "    epochs=20,\n",
        "    batch_size=512,\n",
        "    validation_data=(x_val, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJnGNYD8dwun"
      },
      "source": [
        "**Plot the training and validation loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5_yJexEd5zn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_validation_results(training_results, validation_results,\n",
        "                                     title, ylabel):\n",
        "  print(\"training: \", training_results)\n",
        "  print(\"validation: \", validation_results)\n",
        "  plt.clf()\n",
        "  epochs = range(1, len(training_results)+1)\n",
        "  plt.plot(epochs, training_results, \"bo\", label=\"Training\")\n",
        "  plt.plot(epochs, validation_results, \"b\", label=\"Validation\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0yJp_2ZgljA"
      },
      "outputs": [],
      "source": [
        "history_dict = history.history\n",
        "training_loss_values = history_dict[\"loss\"]\n",
        "validation_loss_values = history_dict[\"val_loss\"]\n",
        "plot_training_validation_results(training_loss_values, validation_loss_values,\n",
        "                                 \"Training and validation loss\", \"Loss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dni-fsHghGf4"
      },
      "outputs": [],
      "source": [
        "training_acc = history_dict[\"accuracy\"]\n",
        "validation_acc = history_dict[\"val_accuracy\"]\n",
        "plot_training_validation_results(training_acc, validation_acc,\n",
        "                                 \"Training and validation accuracy\",\n",
        "                                 \"Accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GavVBkAXd5-X"
      },
      "source": [
        "**Refine the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUP8Gz8md-wC"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential(\n",
        "    [#TODO,\n",
        "     #TODO,\n",
        "     #TODO\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"#TODO\",\n",
        "    loss=\"#TODO\",\n",
        "    metrics=[\"#TODO\"]\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=#TODO,\n",
        "    batch_size=512\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nDALc-8Wz9w"
      },
      "source": [
        "#Predict new data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy0V5X05W3RA"
      },
      "outputs": [],
      "source": [
        "model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIBTSOE4kLbW"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(x_test, y_test)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arGEf-lCv7yr"
      },
      "source": [
        "#Other experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GaksPMq2fKG"
      },
      "source": [
        "##Consider the baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QQj3bSDwFzJ"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "test_labels_copy = copy.copy(test_labels)\n",
        "np.random.shuffle(test_labels_copy)\n",
        "hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
        "hits_array.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjUwtXj7wbRU"
      },
      "outputs": [],
      "source": [
        "results = np.zeros(46)\n",
        "for label in test_labels:\n",
        "  results[label] += 1\n",
        "print(results)\n",
        "print(max(results))\n",
        "print(max(results) / sum(results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14CmaApMxWeb"
      },
      "outputs": [],
      "source": [
        "results = np.zeros(46)\n",
        "for label in train_labels:\n",
        "  results[label] += 1\n",
        "print(results)\n",
        "print(max(results))\n",
        "print(max(results) / sum(results))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_Gl2QGk2i0F"
      },
      "source": [
        "##Information bottleneck"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHtzzeo12nfw"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential(\n",
        "    [layers.Dense(64, activation=\"relu\"),\n",
        "     layers.Dense(4, activation=\"relu\"),\n",
        "     layers.Dense(46, activation=\"softmax\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"#TODO\",\n",
        "    loss=\"#TODO\",\n",
        "    metrics=[\"#TODO\"]\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    partial_x_train,\n",
        "    partial_y_train,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_val, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMwR7AGd3pZx"
      },
      "source": [
        "##Different way to handle the labels and the loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-0HGsP73uDZ"
      },
      "outputs": [],
      "source": [
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgelcYnG39bc"
      },
      "outputs": [],
      "source": [
        "y_val = y_train[:1000]\n",
        "partial_y_train = y_train[1000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWgc1XwU4JsW"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential(\n",
        "    [layers.Dense(64, activation=\"relu\"),\n",
        "     layers.Dense(64, activation=\"relu\"),\n",
        "     layers.Dense(46, activation=\"softmax\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"#TODO\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"#TODO\"]\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    partial_x_train,\n",
        "    partial_y_train,\n",
        "    epochs=20,\n",
        "    batch_size=512,\n",
        "    validation_data=(x_val, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TT6yyeiy4o_n"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential(\n",
        "    [layers.Dense(64, activation=\"relu\"),\n",
        "     layers.Dense(64, activation=\"relu\"),\n",
        "     layers.Dense(46, activation=\"softmax\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=9,\n",
        "    batch_size=512\n",
        ")\n",
        "\n",
        "results = model.evaluate(x_test, y_test)\n",
        "print(results)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
