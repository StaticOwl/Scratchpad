{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/staticowl/miniconda3//lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0675\n",
      "Epoch [200/1000], Loss: 0.0145\n",
      "Epoch [300/1000], Loss: 0.0004\n",
      "Epoch [400/1000], Loss: 0.0000\n",
      "Epoch [500/1000], Loss: 0.0000\n",
      "Epoch [600/1000], Loss: 0.0001\n",
      "Epoch [700/1000], Loss: 0.0000\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.0000\n",
      "Converted Feature: [0.51578826 0.2001884  0.69031364 0.02166189 0.5159407  0.3202289\n",
      " 0.8360705  0.53537214 0.7203905  0.9234433  0.65337014 0.84394044\n",
      " 0.5880028  0.18579386 0.64804876 0.13330191 0.7680859  0.93606985\n",
      " 0.8281777  0.10790095 0.34701195 0.7901224  0.21725005 0.27404773\n",
      " 0.1890176  0.0885486  0.5766597  0.30678824 0.35581806 0.14792757\n",
      " 0.71813244 0.4264056  0.4423367  0.3240838  0.70782644 0.3428624\n",
      " 0.86315185 0.46705362 0.96288645 0.48173457 0.7110623  0.78102577\n",
      " 0.60397464 0.16133423 0.22240531 0.5163418  0.2355866  0.34963\n",
      " 0.9228073  0.36901793 0.15199684 0.3641538  0.5419421  0.12549558\n",
      " 0.14360194 0.08012033 0.7282584  0.5747153  0.6133456  0.2168256\n",
      " 0.4788234  0.45389116 0.17785878 0.43976426 0.9151567  0.36235595\n",
      " 0.5358619  0.3855794  0.08731718 0.39646688 0.28886446 0.7043759\n",
      " 0.971401   0.92911714 0.55035204 0.547929   0.5920176  0.80233026\n",
      " 0.52703184 0.10879517 0.09442636 0.4357068  0.82649815 0.11562178\n",
      " 0.42900264 0.18687874 0.5892388  0.7335467  0.39355457 0.739368\n",
      " 0.38807476 0.55506545 0.1312154  0.38362136 0.22166787 0.40467387\n",
      " 0.76919997 0.2879769  0.8368628  0.06186062 0.3521778  0.4690975\n",
      " 0.96366024 0.3526781  0.98206425 0.3722272  0.69161224 0.41636163\n",
      " 0.17971657 0.5691532  0.3936498  0.13796288 0.47957483 0.78782964\n",
      " 0.845551   0.65424687 0.26408914 0.10422191 0.9665911  0.8703368\n",
      " 0.9689345  0.40121123 0.01036053 0.11014625 0.04047013 0.85225075\n",
      " 0.4332928  0.91966605]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "# Load and preprocess dataset\n",
    "\n",
    "# You may need to use librosa or other audio processing libraries for feature extraction\n",
    "\n",
    "# Model architecture (Variational Autoencoder for simplicity)\n",
    "class VoiceConversionModel(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(VoiceConversionModel, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, latent_dim),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "# Define hyperparameters\n",
    "input_dim = 128 \n",
    "latent_dim = 64  \n",
    "\n",
    "\n",
    "model = VoiceConversionModel(input_dim, latent_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = torch.tensor(X_train, dtype=torch.float32)\n",
    "    targets = torch.tensor(Y_train, dtype=torch.float32)\n",
    "    optimizer.zero_grad()\n",
    "    _, outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "input_feature = torch.tensor(X_train[0], dtype=torch.float32)\n",
    "_, converted_feature_raw = model(input_feature)\n",
    "converted_feature = converted_feature_raw.detach().numpy()\n",
    "print(\"Converted Feature:\", converted_feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of spectrogram: (128,)\n",
      "Data type of spectrogram: float32\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/staticowl/winHome/Code/myProjects/scratchpad/voice_train_using_model.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/staticowl/winHome/Code/myProjects/scratchpad/voice_train_using_model.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     waveform \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mgriffinlim(np\u001b[39m.\u001b[39mabs(spectrogram))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/staticowl/winHome/Code/myProjects/scratchpad/voice_train_using_model.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m waveform\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/staticowl/winHome/Code/myProjects/scratchpad/voice_train_using_model.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m converted_audio \u001b[39m=\u001b[39m spectrogram_to_audio(converted_feature)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/staticowl/winHome/Code/myProjects/scratchpad/voice_train_using_model.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m sf\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39moutput.wav\u001b[39m\u001b[39m\"\u001b[39m, converted_audio, \u001b[39m128\u001b[39m)\n",
      "\u001b[1;32m/home/staticowl/winHome/Code/myProjects/scratchpad/voice_train_using_model.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/staticowl/winHome/Code/myProjects/scratchpad/voice_train_using_model.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mShape of spectrogram:\u001b[39m\u001b[39m\"\u001b[39m, spectrogram\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/staticowl/winHome/Code/myProjects/scratchpad/voice_train_using_model.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mData type of spectrogram:\u001b[39m\u001b[39m\"\u001b[39m, spectrogram\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/staticowl/winHome/Code/myProjects/scratchpad/voice_train_using_model.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m waveform \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mgriffinlim(np\u001b[39m.\u001b[39;49mabs(spectrogram))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/staticowl/winHome/Code/myProjects/scratchpad/voice_train_using_model.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mreturn\u001b[39;00m waveform\n",
      "File \u001b[0;32m~/.local/bin/.virtualenvs/tf/lib/python3.10/site-packages/librosa/core/spectrum.py:2669\u001b[0m, in \u001b[0;36mgriffinlim\u001b[0;34m(S, n_iter, hop_length, win_length, n_fft, window, center, dtype, length, pad_mode, momentum, init, random_state)\u001b[0m\n\u001b[1;32m   2667\u001b[0m \u001b[39m# Infer n_fft from the spectrogram shape\u001b[39;00m\n\u001b[1;32m   2668\u001b[0m \u001b[39mif\u001b[39;00m n_fft \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2669\u001b[0m     n_fft \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m (S\u001b[39m.\u001b[39;49mshape[\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m   2671\u001b[0m \u001b[39m# Infer the dtype from S\u001b[39;00m\n\u001b[1;32m   2672\u001b[0m angles \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(S\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mutil\u001b[39m.\u001b[39mdtype_r2c(S\u001b[39m.\u001b[39mdtype))\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def spectrogram_to_audio(spectrogram):\n",
    "    # Inverse transform spectrogram to waveform using Griffin-Lim\n",
    "\n",
    "    print(\"Shape of spectrogram:\", spectrogram.shape)\n",
    "    print(\"Data type of spectrogram:\", spectrogram.dtype)\n",
    "    waveform = librosa.griffinlim(np.abs(spectrogram))\n",
    "    return waveform\n",
    "\n",
    "converted_audio = spectrogram_to_audio(converted_feature)\n",
    "sf.write(\"output.wav\", converted_audio, 128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
